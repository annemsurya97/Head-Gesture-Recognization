*Head Gesture Recognition using 6DOF Inertial Sensors*

This project demonstrates how head gestures can be recognized from inertial sensor data (Roll, Pitch, Yaw, and Time) using machine learning and deep learning models.

We built an interactive Tkinter-based desktop app that lets you:
âœ” Upload and preprocess sensor data
âœ” Train and evaluate models (Perceptron, MLP, and DNN+RF hybrid)
âœ” Visualize performance metrics and confusion matrices
âœ” Compare models in a single graph
âœ” Predict gestures on new test data

ğŸ“‚ Dataset Example

The dataset is a time-series of head movements captured as Roll, Pitch, and Yaw. Each row represents one reading, labeled with a gesture (Miscare).

Roll,Pitch,Yaw,Miscare,Time
4,-3,0,MoveRight_2s,0
4,-3,0,MoveRight_2s,0.02
5,-3,-1,MoveRight_2s,0.04
6,-2,-6,MoveRight_2s,0.34
8,-2,-18,MoveRight_2s,0.72


Roll, Pitch, Yaw â†’ Head orientation (sensor readings)

Miscare â†’ Gesture label (e.g., MoveRight_2s)

Time â†’ Timestamp of reading

âš™ï¸ Features

ğŸ“ Upload Dataset â€“ load CSV files of sensor data

ğŸ§¹ Preprocess Data â€“ clean missing values, balance dataset with SMOTE, split into train/test

ğŸ¤– Train Models:

Perceptron Classifier

MLP Classifier

DNN with Random Forest Classifier (hybrid)

ğŸ“Š Performance Metrics â€“ accuracy, precision, recall, F1-score

ğŸ“ˆ Comparison Graph â€“ side-by-side comparison of models

ğŸ”® Prediction Mode â€“ test on new unseen data

ğŸš€ How It Works

Data Upload & Cleaning

Load dataset in .csv format

Handle missing values and label encode gestures

Data Balancing

Use SMOTE (Synthetic Minority Over-sampling Technique) to balance class distribution

Training Models

Perceptron â†’ baseline linear model

MLP â†’ neural network for classification

DNN+RF â†’ deep feature extractor + random forest classifier

Evaluation

Metrics: Accuracy, Precision, Recall, F1-score

Visualizations: Confusion Matrix, ROC Curve, Performance Bar Graph

Prediction

Load new sensor data

Predict gesture labels

ğŸ› ï¸ Installation

Make sure you have Python 3.8+ installed.

# Install dependencies
pip install -r requirements.txt

ğŸ“¦ Requirements

numpy

pandas

seaborn

matplotlib

scikit-learn

imblearn

tensorflow

tkinter (comes pre-installed with Python on most systems)

â–¶ï¸ Run the Application
python main.py


This will launch the Tkinter GUI:

Upload your dataset

Preprocess it

Train models

Compare results

Run predictions on new data

ğŸ“Š Example Output

Confusion Matrix
<img width="956" height="751" alt="Perceptron" src="https://github.com/user-attachments/assets/72cf9257-1e98-4228-bb84-9ac4e0f24279" />
<img width="500" height="500" alt="MLP" src="https://github.com/user-attachments/assets/a6ee664d-c834-4f8b-a877-26e52ea7ae71" />
<img width="867" height="751" alt="DNN" src="https://github.com/user-attachments/assets/43e4b069-d071-4e7f-8e4e-1e4c5ccabd7d" />

Model Comparison Graph
<img width="1000" height="600" alt="Comaparision Graph" src="https://github.com/user-attachments/assets/57414838-23f4-4b54-aa2b-1a284eb7a1ff" />

